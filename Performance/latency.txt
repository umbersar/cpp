Some ideas: https://github.com/LucaCanali/Miscellaneous/blob/master/Spark_Notes/Tools_Linux_Memory_Perf_Measure.md

==============================================================================================================================

From: http://norvig.com/21-days.html

Approximate timing for various operations on a typical PC:
execute typical instruction	1/1,000,000,000 sec = 1 nanosec
fetch from L1 cache memory	0.5 nanosec
branch misprediction	5 nanosec
fetch from L2 cache memory	7 nanosec
Mutex lock/unlock	25 nanosec
fetch from main memory	100 nanosec
send 2K bytes over 1Gbps network	20,000 nanosec
read 1MB sequentially from memory	250,000 nanosec
fetch from new disk location (seek)	8,000,000 nanosec
read 1MB sequentially from disk	20,000,000 nanosec
send packet US to Europe and back	150 milliseconds = 150,000,000 nanosec


================================================================================================================================

From: https://gist.github.com/jboner/2841832

Latency Comparison Numbers (~2012)
----------------------------------
L1 cache reference                           0.5 ns
Branch mispredict                            5   ns
L2 cache reference                           7   ns                      14x L1 cache
Mutex lock/unlock                           25   ns
Main memory reference                      100   ns                      20x L2 cache, 200x L1 cache
Compress 1K bytes with Zippy             3,000   ns        3 us
Send 1K bytes over 1 Gbps network       10,000   ns       10 us
Read 4K randomly from SSD*             150,000   ns      150 us          ~1GB/sec SSD
Read 1 MB sequentially from memory     250,000   ns      250 us
Round trip within same datacenter      500,000   ns      500 us
Read 1 MB sequentially from SSD*     1,000,000   ns    1,000 us    1 ms  ~1GB/sec SSD, 4X memory
Disk seek                           10,000,000   ns   10,000 us   10 ms  20x datacenter roundtrip
Read 1 MB sequentially from disk    20,000,000   ns   20,000 us   20 ms  80x memory, 20X SSD
Send packet CA->Netherlands->CA    150,000,000   ns  150,000 us  150 ms

Notes
-----
1 ns = 10^-9 seconds
1 us = 10^-6 seconds = 1,000 ns
1 ms = 10^-3 seconds = 1,000 us = 1,000,000 ns

Credit
------
By Jeff Dean:               http://research.google.com/people/jeff/
Originally by Peter Norvig: http://norvig.com/21-days.html#answers

Contributions
-------------
'Humanized' comparison:  https://gist.github.com/hellerbarde/2843375
Visual comparison chart: http://i.imgur.com/k0t1e.png

========================================================================================================================================

From: https://github.com/sirupsen/napkin-math

Numbers
Below are numbers that are rounded from runs on a GCP c2-standard-4 (Intel Cascade) and 2017 Macbook (2.8GHz, quad-core).

Note 1: Numbers have been rounded, which means they don't line up perfectly. Note 2: Some throughput and latency numbers don't line up (for ease of calculations see exact results e.g. here).

Operation	Latency	Throughput	1 MiB	1 GiB
Sequential Memory R/W (64 bytes)	5 ns	10 GiB/s	100 μs	100 ms
Hashing, not crypto-safe (64 bytes)	25 ns	2 GiB/s	500 μs	500 ms
Random Memory R/W (64 bytes)	50 ns	1 GiB/s	1 ms	1 s
Fast Serialization [8] [9] †	N/A	1 GiB/s	1 ms	1s
Fast Deserialization [8] [9] †	N/A	1 GiB/s	1 ms	1s
System Call	500 ns	N/A	N/A	N/A
Hashing, crypto-safe (64 bytes)	500 ns	200 MiB/s	10 ms	10s
Sequential SSD read (8 KiB)	1 μs	4 GiB/s	200 μs	200 ms
Context Switch [1] [2]	10 μs	N/A	N/A	N/A
Sequential SSD write, -fsync (8KiB)	10 μs	1 GiB/s	1 ms	1 s
TCP Echo Server (32 KiB)	10 μs	4 GiB/s	200 μs	200 ms
Sequential SSD write, +fsync (8KiB)	1 ms	10 MiB/s	100 ms	2 min
Sorting (64-bit integers)	N/A	200 MiB/s	5 ms	5 s
Random SSD Seek (8 KiB)	100 μs	70 MiB/s	15 ms	15 s
Compression [3]	N/A	100 MiB/s	10 ms	10s
Decompression [3]	N/A	200 MiB/s	5 ms	5s
Serialization [8] [9] †	N/A	100 MiB/s	10 ms	10s
Deserialization [8] [9] †	N/A	100 MiB/s	10 ms	10s
Proxy: Envoy/ProxySQL/Nginx/HAProxy	50 μs	?	?	?
Network within same region [6]	250 μs	100 MiB/s	10 ms	10s
{MySQL, Memcached, Redis, ..} Query	500 μs	?	?	?
Random HDD Seek (8 KiB)	10 ms	70 MiB/s	15 ms	15 s
Network between regions [6]	Varies	25 MiB/s	40 ms	40s
Network NA East <-> West	60 ms	25 MiB/s	40 ms	40s
Network EU West <-> NA East	80 ms	25 MiB/s	40 ms	40s
Network NA West <-> Singapore	180 ms	25 MiB/s	40 ms	40s
Network EU West <-> Singapore	160 ms	25 MiB/s	40 ms	40s
†: "Fast serialization/deserialization" is typically a simple wire-protocol that just dumps bytes, or a very efficient environment. Typically standard serialization such as e.g. JSON will be of the slower kind. We include both here as serialization/deserialization is a very, very broad topic with extremely different performance characteristics depending on data and implementation.

You can run this with RUSTFLAGS='-C target-cpu=native' cargo run --release -- -h. You won't get the right numbers when you're compiling in debug mode. You can help this project by adding new suites and filling out the blanks.

I am aware of some inefficiencies in this suite. I intend to improve my skills in this area, in order to ensure the numbers are the upper-bound of performance you may be able to squeeze out in production. I find it highly unlikely any of them will be more than 2-3x off, which shouldn't be a problem for most users.

Cost Numbers
Approximate numbers that should be consistent between Cloud providers.

What	Amount	$ / Month	$ / Hour
CPU	1	$10	$0.02
Memory	1 GB	$1	
SSD	1 GB	$0.1	
Disk	1 GB	$0.01	
S3, GCS, ..	1 GB	$0.01	
Network	1 GB	$0.01	
Compression Ratios
This is sourced from a few sources. [3] [4] [5] Note that compression speeds (but generally not ratios) vary by an order of magnitude depending on the algorithm and the level of compression (which trades speed for compression).

I typically ballpark that another x in compression ratio decreases performance by 10x. E.g. we can get a 2x ratio on English Wikipedia at ~200 MiB/s, and 3x at ~20MiB/s, and 4x at 1MB/s.

What	Compression Ratio
HTML	2-3x
English	2-4x
Source Code	2-4x
Executables	2-3x
RPC	5-10x
Techniques
Don't overcomplicate. If you are basing your calculation on more than 6 assumptions, you're likely making it harder than it should be.
Keep the units. They're good checksumming. Wolframalpha has terrific support if you need a hand in converting e.g. KiB to TiB.
Calculate with exponents. A lot of back-of-the-envelope calculations are done with just coefficients and exponents, e.g. c * 10^e. Your goal is to get within an order of magnitude right--that's just e. c matters a lot less. Only worrying about single-digit coefficients and exponents makes it much easier on a napkin (not to speak of all the zeros you avoid writing).
Perform Fermi decomposition. Write down things you can guess at until you can start to hint at an answer. When you want to know the cost of storage for logging, you're going to want to know how big a log line is, how many of those you have per second, what that costs, and so on.
